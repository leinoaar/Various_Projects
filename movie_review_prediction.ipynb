{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/intro-to-nlp/blob/master/course_project_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucyWlC5gbOyR"
      },
      "source": [
        "# Introduction to HLT Project\n",
        "\n",
        "- Student Name: Aaron Leino\n",
        "- Date: 6.5.2025\n",
        "- Chosen Corpus: Stanford Sentiment Treebank (SST-2)\n",
        "\n",
        "### Corpus information\n",
        "\n",
        "- Description of the chosen corpus: The Stanford Sentiment Treebank contains movie review sentences from Rotten Tomatoes. The reviews are annotated with binary sentiment labels: positive and negative.\n",
        "- Paper(s) and other published materials related to the corpus: Socher et al., 2013: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\n",
        "- State-of-the-art performance (best published results) on this corpus: T5-11B and MT-DNN-SMART, both with 97.5% accuracy. (Papers With Code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5d-9uxrcDY-"
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "caHHQoqEcG1J"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets transformers evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovUapilSb8iT"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Data download and preprocessing\n",
        "\n",
        "### 2.1. Download the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PDx40YyzbGPc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence', 'label', 'idx'],\n",
            "        num_rows: 67349\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['sentence', 'label', 'idx'],\n",
            "        num_rows: 872\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence', 'label', 'idx'],\n",
            "        num_rows: 1821\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXb7CQNCbZOI"
      },
      "source": [
        "### 2.2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RO5BXCuRbYKr"
      },
      "outputs": [],
      "source": [
        "# Use DistilBERT as tokenizer\n",
        "\n",
        "distilbert = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(distilbert)\n",
        "\n",
        "# Tokenize sentences\n",
        "def tokenize_func(inputdata):\n",
        "    return tokenizer(inputdata[\"sentence\"], truncation = True, padding = \"max_length\", max_length=128)\n",
        "tokenized_dataset = dataset.map(tokenize_func, batched=True)\n",
        "\n",
        "# The test set does not have labels so I split the train data.\n",
        "split1 = tokenized_dataset[\"train\"].train_test_split(test_size=200, seed=2025)\n",
        "test_dataset = split1[\"test\"]  \n",
        "remaining_train = split1[\"train\"] \n",
        "train_dataset = remaining_train.select(range(1000))\n",
        "\n",
        "validation_dataset = tokenized_dataset[\"validation\"].select(range(200))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ntHh_JbrAg"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Machine learning model\n",
        "\n",
        "### 3.1. Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Hs2Bf49zbn5C"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define accuracy metrics\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlO8RVuHcmAh"
      },
      "source": [
        "### 3.2 Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IzDrTDd0cWOG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-05-07 11:14:41,290] A new study created in memory with name: no-name-7eef530c-c6c9-4846-b96d-9eaf835bb3bc\n",
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5075, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.4407897889614105, 'eval_accuracy': 0.8, 'eval_runtime': 5.5042, 'eval_samples_per_second': 36.336, 'eval_steps_per_second': 4.542, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1864, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6523927450180054, 'eval_accuracy': 0.79, 'eval_runtime': 4.7747, 'eval_samples_per_second': 41.887, 'eval_steps_per_second': 5.236, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.045, 'learning_rate': 0.0, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:20:31,150] Trial 0 finished with value: 0.83 and parameters: {'learning_rate': 5e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 8, 'weight_decay': 0.002314276187863276}. Best is trial 0 with value: 0.83.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.8185315132141113, 'eval_accuracy': 0.83, 'eval_runtime': 5.0142, 'eval_samples_per_second': 39.887, 'eval_steps_per_second': 4.986, 'epoch': 3.0}\n",
            "{'train_runtime': 349.4683, 'train_samples_per_second': 8.584, 'train_steps_per_second': 1.073, 'train_loss': 0.24630388641357423, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6155, 'learning_rate': 1e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.48285767436027527, 'eval_accuracy': 0.8, 'eval_runtime': 5.6789, 'eval_samples_per_second': 35.218, 'eval_steps_per_second': 4.402, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3388, 'learning_rate': 0.0, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:24:10,657] Trial 1 finished with value: 0.785 and parameters: {'learning_rate': 2e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 1.6968814162145983e-05}. Best is trial 0 with value: 0.83.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.42116352915763855, 'eval_accuracy': 0.785, 'eval_runtime': 5.2289, 'eval_samples_per_second': 38.249, 'eval_steps_per_second': 4.781, 'epoch': 2.0}\n",
            "{'train_runtime': 219.0378, 'train_samples_per_second': 9.131, 'train_steps_per_second': 0.575, 'train_loss': 0.47712254902673146, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.559, 'learning_rate': 1.5e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.4359535276889801, 'eval_accuracy': 0.815, 'eval_runtime': 5.0999, 'eval_samples_per_second': 39.216, 'eval_steps_per_second': 4.902, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.267, 'learning_rate': 0.0, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:27:53,845] Trial 2 finished with value: 0.8 and parameters: {'learning_rate': 3e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 6.146881799785113e-06}. Best is trial 0 with value: 0.83.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4291819632053375, 'eval_accuracy': 0.8, 'eval_runtime': 5.2897, 'eval_samples_per_second': 37.81, 'eval_steps_per_second': 4.726, 'epoch': 2.0}\n",
            "{'train_runtime': 222.7167, 'train_samples_per_second': 8.98, 'train_steps_per_second': 0.566, 'train_loss': 0.4129905246552967, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.559, 'learning_rate': 1.5e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.4359535276889801, 'eval_accuracy': 0.815, 'eval_runtime': 5.1646, 'eval_samples_per_second': 38.725, 'eval_steps_per_second': 4.841, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.267, 'learning_rate': 0.0, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:31:34,524] Trial 3 finished with value: 0.8 and parameters: {'learning_rate': 3e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 0.00010167643831554165}. Best is trial 0 with value: 0.83.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4291819632053375, 'eval_accuracy': 0.8, 'eval_runtime': 5.3636, 'eval_samples_per_second': 37.288, 'eval_steps_per_second': 4.661, 'epoch': 2.0}\n",
            "{'train_runtime': 220.2741, 'train_samples_per_second': 9.08, 'train_steps_per_second': 0.572, 'train_loss': 0.4129905246552967, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5323, 'learning_rate': 2.5e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.39774540066719055, 'eval_accuracy': 0.8, 'eval_runtime': 5.3571, 'eval_samples_per_second': 37.333, 'eval_steps_per_second': 4.667, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2026, 'learning_rate': 0.0, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:35:13,439] Trial 4 finished with value: 0.805 and parameters: {'learning_rate': 5e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 0.002134381267111705}. Best is trial 0 with value: 0.83.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.49984779953956604, 'eval_accuracy': 0.805, 'eval_runtime': 5.1832, 'eval_samples_per_second': 38.586, 'eval_steps_per_second': 4.823, 'epoch': 2.0}\n",
            "{'train_runtime': 218.093, 'train_samples_per_second': 9.17, 'train_steps_per_second': 0.578, 'train_loss': 0.36744473472474115, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5113, 'learning_rate': 1.5e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.4693756401538849, 'eval_accuracy': 0.805, 'eval_runtime': 14.1161, 'eval_samples_per_second': 14.168, 'eval_steps_per_second': 1.771, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2271, 'learning_rate': 0.0, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:41:30,916] Trial 5 finished with value: 0.8 and parameters: {'learning_rate': 3e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'weight_decay': 6.319186005153657e-05}. Best is trial 0 with value: 0.83.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5429187417030334, 'eval_accuracy': 0.8, 'eval_runtime': 13.3434, 'eval_samples_per_second': 14.989, 'eval_steps_per_second': 1.874, 'epoch': 2.0}\n",
            "{'train_runtime': 376.7123, 'train_samples_per_second': 5.309, 'train_steps_per_second': 0.664, 'train_loss': 0.36920738220214844, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5019, 'learning_rate': 2.5e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.4312130808830261, 'eval_accuracy': 0.81, 'eval_runtime': 13.2333, 'eval_samples_per_second': 15.113, 'eval_steps_per_second': 1.889, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1818, 'learning_rate': 0.0, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:49:15,222] Trial 6 finished with value: 0.82 and parameters: {'learning_rate': 5e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'weight_decay': 0.00011899112437839468}. Best is trial 0 with value: 0.83.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6180638074874878, 'eval_accuracy': 0.82, 'eval_runtime': 4.3194, 'eval_samples_per_second': 46.303, 'eval_steps_per_second': 5.788, 'epoch': 2.0}\n",
            "{'train_runtime': 463.724, 'train_samples_per_second': 4.313, 'train_steps_per_second': 0.539, 'train_loss': 0.3418203659057617, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.511, 'learning_rate': 1.5e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.4685359299182892, 'eval_accuracy': 0.805, 'eval_runtime': 4.7016, 'eval_samples_per_second': 42.539, 'eval_steps_per_second': 5.317, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.2266, 'learning_rate': 0.0, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:52:56,608] Trial 7 finished with value: 0.8 and parameters: {'learning_rate': 3e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'weight_decay': 0.00478185475363006}. Best is trial 0 with value: 0.83.\n",
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5440424680709839, 'eval_accuracy': 0.8, 'eval_runtime': 4.4799, 'eval_samples_per_second': 44.644, 'eval_steps_per_second': 5.58, 'epoch': 2.0}\n",
            "{'train_runtime': 220.9718, 'train_samples_per_second': 9.051, 'train_steps_per_second': 1.131, 'train_loss': 0.36881552124023437, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.559, 'learning_rate': 1.5e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.4359535276889801, 'eval_accuracy': 0.815, 'eval_runtime': 4.4489, 'eval_samples_per_second': 44.955, 'eval_steps_per_second': 5.619, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.267, 'learning_rate': 0.0, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:56:14,302] Trial 8 finished with value: 0.8 and parameters: {'learning_rate': 3e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 16, 'weight_decay': 0.0009414577897716729}. Best is trial 0 with value: 0.83.\n",
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4291819632053375, 'eval_accuracy': 0.8, 'eval_runtime': 4.4205, 'eval_samples_per_second': 45.244, 'eval_steps_per_second': 5.655, 'epoch': 2.0}\n",
            "{'train_runtime': 197.3346, 'train_samples_per_second': 10.135, 'train_steps_per_second': 0.639, 'train_loss': 0.4129905246552967, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5556, 'learning_rate': 1.9999999999999998e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 11:57:53,261] Trial 9 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.47725075483322144, 'eval_accuracy': 0.775, 'eval_runtime': 4.4775, 'eval_samples_per_second': 44.668, 'eval_steps_per_second': 5.584, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5076, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 12:00:30,516] Trial 10 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4480636715888977, 'eval_accuracy': 0.8, 'eval_runtime': 13.4333, 'eval_samples_per_second': 14.888, 'eval_steps_per_second': 1.861, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\leino\\AppData\\Local\\Temp\\ipykernel_18212\\2038782950.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5078, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-07 12:05:05,203] Trial 11 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4426151216030121, 'eval_accuracy': 0.8, 'eval_runtime': 13.4545, 'eval_samples_per_second': 14.865, 'eval_steps_per_second': 1.858, 'epoch': 1.0}\n",
            "Best hyperparameters: {'learning_rate': 5e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 8, 'weight_decay': 0.002314276187863276}\n"
          ]
        }
      ],
      "source": [
        "def model_init(): #for initializing a fresh model each time\n",
        "    return AutoModelForSequenceClassification.from_pretrained(distilbert, num_labels=2)\n",
        "\n",
        "# use optuna for parameter optimization\n",
        "# define parameter space for optuna \n",
        "\n",
        "def optuna_hp_space(ex):\n",
        "    return {\n",
        "      \"learning_rate\": ex.suggest_categorical(\"learning_rate\", [2e-5, 3e-5, 5e-5]),\n",
        "      \"num_train_epochs\": ex.suggest_int(\"num_train_epochs\", 2, 3),\n",
        "      \"per_device_train_batch_size\": ex.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
        "      \"weight_decay\": ex.suggest_loguniform(\"weight_decay\", 1e-6, 1e-1),\n",
        "    }\n",
        "\n",
        "#define the base arguments for optuna\n",
        "base_args = TrainingArguments(\n",
        "    output_dir=\"./optuna_results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",               \n",
        "    load_best_model_at_end=False,     \n",
        "    disable_tqdm=True\n",
        ")\n",
        "\n",
        "# hyperparameter search\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=base_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "best_run = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    n_trials=12,\n",
        "    hp_space=optuna_hp_space,\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Best hyperparameters:\", best_run.hyperparameters)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EzCYTnfcrvN"
      },
      "source": [
        "### 3.3. Evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BG7s-yr6crGF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4702, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n",
            "{'eval_loss': 0.15192928910255432, 'eval_accuracy': 0.9525, 'eval_runtime': 30.2194, 'eval_samples_per_second': 39.71, 'eval_steps_per_second': 4.964, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1774, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n",
            "{'eval_loss': 0.035744521766901016, 'eval_accuracy': 0.9925, 'eval_runtime': 26.4285, 'eval_samples_per_second': 45.406, 'eval_steps_per_second': 5.676, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0567, 'learning_rate': 0.0, 'epoch': 3.0}\n",
            "{'eval_loss': 0.018343310803174973, 'eval_accuracy': 0.9958333333333333, 'eval_runtime': 26.626, 'eval_samples_per_second': 45.069, 'eval_steps_per_second': 5.634, 'epoch': 3.0}\n",
            "{'train_runtime': 464.9755, 'train_samples_per_second': 7.742, 'train_steps_per_second': 0.968, 'train_loss': 0.2347829967074924, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\leino\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7507790923118591, 'eval_accuracy': 0.835, 'eval_runtime': 4.3702, 'eval_samples_per_second': 45.765, 'eval_steps_per_second': 5.721, 'epoch': 3.0}\n",
            "Test accuracy: 0.835\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# define the best model by the previous optimization\n",
        "# Extract the best parameters\n",
        "hp = best_run.hyperparameters\n",
        "best_args = TrainingArguments(\n",
        "    output_dir=\"./best_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=hp[\"learning_rate\"],\n",
        "    per_device_train_batch_size=hp[\"per_device_train_batch_size\"],\n",
        "    num_train_epochs=hp[\"num_train_epochs\"],\n",
        "    weight_decay=hp.get(\"weight_decay\", 0.0),\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    disable_tqdm=True,\n",
        ")\n",
        "\n",
        "# Combine validation and train data for larger training data\n",
        "from datasets import concatenate_datasets\n",
        "full_train = concatenate_datasets([train_dataset, validation_dataset])\n",
        "\n",
        "best_trainer = Trainer(\n",
        "    model_init(),\n",
        "    args= best_args,\n",
        "    train_dataset= full_train,\n",
        "    eval_dataset=full_train,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "#train the model\n",
        "best_trainer.train()\n",
        "\n",
        "# calculate results on test data\n",
        "test_results = best_trainer.evaluate(test_dataset)\n",
        "print(\"Test accuracy:\", test_results[\"eval_accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7ylOS8FdYZ5"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Results and summary\n",
        "\n",
        "### 4.1 Corpus insights\n",
        "\n",
        "(Briefly discuss what you learned about the corpus and its annotation)\n",
        "\n",
        "### 4.2 Results\n",
        "\n",
        "(Briefly summarize your results)\n",
        "\n",
        "### 4.3 Relation to state of the art\n",
        "\n",
        "(Compare your results to the state-of-the-art performance)\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Bonus Task (optional)\n",
        "\n",
        "### 5.1. Annotating out-of-domain documents\n",
        "\n",
        "(Briefly describe the chosen out-of-domain documents)\n",
        "\n",
        "(Briefly describe the process of annotation)\n",
        "\n",
        "### 5.2 Conversion into dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "32DU04FndRdM"
      },
      "outputs": [],
      "source": [
        "# Your code to convert the annotations into a dataset here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ghO4JemeFKK"
      },
      "source": [
        "### 5.3. Model evaluation on out-of-domain test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9tzYWQ_zeCYp"
      },
      "outputs": [],
      "source": [
        "# Your code to evaluate the model on the out-of-domain test set here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XLZlItdePfJ"
      },
      "source": [
        "### 5.4 Bonus task results\n",
        "\n",
        "(Present the results of the evaluation on the out-of-domain test set)\n",
        "\n",
        "### 5.5. Annotated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L2YJsiIGeYRe"
      },
      "outputs": [],
      "source": [
        "# Include your annotated out-of-domain data here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
